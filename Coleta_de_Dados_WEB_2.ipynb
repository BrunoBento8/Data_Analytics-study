{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coleta_de_Dados_WEB_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrunoBento8/Data_Analytics-study/blob/main/Coleta_de_Dados_WEB_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GABI6OW8OfQ2"
      },
      "source": [
        "# **Exercícios**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWgNoJN8DHyY"
      },
      "source": [
        "## 1\\. Filmes populares do IMDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YynK1vf2DHyj"
      },
      "source": [
        "O [IMDB](https://www.imdb.com/) é um famoso site de `reviews` de filmes e seriados. Uma das páginas mais acessadas do website é o ranking de filmes mais bem votados. Neste exercício, vamos extrair informações deste website:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeaaM3Ooon2G"
      },
      "source": [
        "### **1.1. Arquivo Robots.txt** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyFPpQrxotDW"
      },
      "source": [
        "Utilize o pacote Python `requests` para fazer o download do conteúdo do arquivo `robots.txt` do site do IMDB e salve numa variável chamada `robots`, este é o link:\n",
        "\n",
        "```\n",
        "https://www.imdb.com/robots.txt\n",
        "```\n",
        "\n",
        "Com o conteúdo na variável `robots`, verifique se a palavra `top` ou `charts` está presente no conteúdo do texto. Se sim, imprima `True`, senão imprima `False`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-AN5ooupsy8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acb984ae-a1f2-4ed1-a5a2-2526213075d6"
      },
      "source": [
        "# solução do exercício 1.1\n",
        "\n",
        "import requests\n",
        "import re\n",
        "\n",
        "URL = 'https://www.imdb.com/robots.txt'\n",
        "robots = requests.get(URL)\n",
        "\n",
        "if re.findall('top', robots.text) or re.findall('top', robots.text) == True:\n",
        "  print('True')\n",
        "\n",
        "else:\n",
        "  print('False')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-1ROo0x2a2B"
      },
      "source": [
        "**Dica**: Você pode colar o endereço do arquivo robots.txt no seu navegador para visualizar o conteúdo do arquivo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH96bDUUpyR-"
      },
      "source": [
        "### **1.2. Crawling & Scraping** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5OD3s6jp4BF"
      },
      "source": [
        "Utilize os pacotes Python `requests` e `beautifulsoup4` para extrair os 10 filmes mais populares do IMDB (titulo, ano e nota), este é o link:\n",
        "\n",
        "```\n",
        "https://www.imdb.com/chart/top/\n",
        "```\n",
        "\n",
        "Escreva os dados extraídos no arquivo csv `imdb.csv` separado por `;` no seguinte formato:\n",
        "\n",
        "```\n",
        "ranking;titulo;ano;nota\n",
        "1;The Shawshank Redemption;1994;9.2\n",
        "2;The Godfather;1972;9.1\n",
        "3;The Godfather: Part II;1974;9.0\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDn0HG6lza1m"
      },
      "source": [
        "**Dica**: O código na letra c já extrai o conteúdo das linhas na lista `textos_coluna`, basta que você extraia o conteúdo de interesse dela. Como exemplo:\n",
        "\n",
        "```python\n",
        "[]\n",
        "['', '1.', '      The Shawshank Redemption', '(1994)', '9.2', '12345678910 ', '', '', '', 'NOT YET RELEASED', ' ', '', 'Seen', '']\n",
        "['', '2.', '      The Godfather', '(1972)', '9.1', '12345678910 ', '', '', '', 'NOT YET RELEASED', ' ', '', 'Seen', '']\n",
        "['', '3.', '      The Godfather: Part II', '(1974)', '9.0', '12345678910 ', '', '', '', 'NOT YET RELEASED', ' ', '', 'Seen', '']\n",
        "['', '4.', '      The Dark Knight', '(2008)', '9.0', '12345678910 ', '', '', '', 'NOT YET RELEASED', ' ', '', 'Seen', '']\n",
        "['', '5.', '      12 Angry Men', '(1957)', '8.9', '12345678910 ', '', '', '', 'NOT YET RELEASED', ' ', '', 'Seen', '']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFuFYv-AxHTl"
      },
      "source": [
        "# a) Utilizando o pacote requests para fazer o download da página na variável conteudo\n",
        "\n",
        "import requests\n",
        "from requests.exceptions import HTTPError\n",
        "\n",
        "conteudo = None\n",
        "URL = 'https://www.imdb.com/chart/top/'\n",
        "\n",
        "conteudo = requests.get(URL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R1nbkktxaGs"
      },
      "source": [
        "# b) Utilizando o pacote beautifulsoup4 para carregar o HTML da variavel conteudo na variavel pagina\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "pagina = BeautifulSoup(conteudo.text, 'html.parser')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa7FMBfsxs5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e94a7c2-e1de-4162-b991-92c3178da697"
      },
      "source": [
        "# c) Utilize o código abaixo para iterar nas linhas e colunas da tabela e preencher a variavel conteudo_extraido\n",
        "conteudo_extraido = []\n",
        "\n",
        "#Acessando a tabela (table) que tem como critério uma class com a palavra chart. No código fonte: <table class=\"chart full-width\" data-caller-name=\"chart-top250movie\">\n",
        "tabela = pagina.find('table', {'class': 'chart'}) #.find() returns only the first child of this tag matching the given criteria {}\n",
        "\n",
        "#Consultar cada elemento que contém a informação do respectivo filme\n",
        "for linha in tabela.find_all('tr'): #tr significa 'table row', no site cada filme tem sua 'tr'\n",
        "  textos_coluna = list()\n",
        "\n",
        "  for coluna in linha.find_all('td'): # A tag td define um dado padrão em uma tabela HTML, logo cada linha \n",
        "    texto_coluna = coluna.get_text().strip().split('\\n') #.get_text() retorna todo o texto da tag, porém vem com o '\\n'\n",
        "    textos_coluna += texto_coluna\n",
        "\n",
        "  #print(textos_coluna)\n",
        "\n",
        "  while textos_coluna:\n",
        "    conteudos_extraidos = textos_coluna[1].replace('.',''), textos_coluna[2].strip(), textos_coluna[3].replace('(','').replace(')',''), textos_coluna[4]\n",
        "    conteudo_extraido.append(conteudos_extraidos)\n",
        "    break\n",
        "    \n",
        "print(conteudo_extraido[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('1', 'The Shawshank Redemption', '1994', '9.2'), ('2', 'The Godfather', '1972', '9.2'), ('3', 'The Dark Knight', '2008', '9.0'), ('4', 'The Godfather Part II', '1974', '9.0'), ('5', '12 Angry Men', '1957', '8.9'), ('6', \"Schindler's List\", '1993', '8.9'), ('7', 'The Lord of the Rings: The Return of the King', '2003', '8.9'), ('8', 'Pulp Fiction', '1994', '8.9'), ('9', 'The Lord of the Rings: The Fellowship of the Ring', '2001', '8.8'), ('10', 'The Good, the Bad and the Ugly', '1966', '8.8')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNd20OxEyIWV"
      },
      "source": [
        "# d) Escrevendo o arquivo imdb.csv com o conteudo da variavel conteudo_extraido\n",
        "import csv\n",
        "\n",
        "with open(file='imdb.csv', mode='w', encoding='utf8') as arquivo:\n",
        "  csv.writer(arquivo, delimiter= ';').writerow(['Ranking', 'Titulo', 'Ano', 'Rating'])\n",
        "  for i in conteudo_extraido:\n",
        "    csv.writer(arquivo, delimiter= ';').writerow(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waxn4B2UDHyl"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0NUUvNgJQXz"
      },
      "source": [
        "## 2\\. Bônus: Projeto em destaque do GitHub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e8HYMAJLA__"
      },
      "source": [
        "Utilize os pacotes Python `requests` e `beautifulsoup4` para extrair os 10 projetos mais populares do GitHub, este é o link:\n",
        "\n",
        "```\n",
        "https://github.com/trending\n",
        "```\n",
        "\n",
        "Escreva os dados extraídos no arquivo csv `github.csv` separado por `;` no seguinte formato:\n",
        "\n",
        "```\n",
        "ranking;project;language;stars;stars_today;forks\n",
        "1;the-book-of-secret-knowledge;;44502;692;4685\n",
        "2;whynotwin11;autoit;2242;1585;117\n",
        "3;lede;c;16732;66;14317\n",
        "```\n",
        "\n",
        "**Nota**: Confira o arquivo `robots.txt` do website."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# solução do exercício 2\n",
        "\n",
        "import requests\n",
        "import re\n",
        "from requests.exceptions import HTTPError\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#Armazenando o download da página na variável conteudo\n",
        "\n",
        "conteudo = None\n",
        "URL = 'https://github.com/trending'\n",
        "\n",
        "conteudo = requests.get(URL)\n",
        "\n",
        "#Carregamento do HTML da variável conteúdo para a variável página\n",
        "\n",
        "pagina = BeautifulSoup(conteudo.text, 'html.parser')\n",
        "\n",
        "#Armazendo o conteudo em lista\n",
        "\n",
        "conteudo_extraido = []\n",
        "\n",
        "infor = pagina.find('div', {'class': 'application-main'})\n",
        "\n",
        "for linha in infor.find_all('article'):\n",
        "  textos_colunas = list()\n",
        "  conteudo = list()\n",
        "    \n",
        "  for coluna in linha.find_all('h1'):\n",
        "    texto_coluna = coluna.get_text().strip().split('\\n')\n",
        "    textos_colunas += texto_coluna\n",
        "  \n",
        "  for coluna in linha.find_all('a'):\n",
        "    texto_coluna = coluna.get_text().strip().split('\\n')\n",
        "    textos_colunas += texto_coluna\n",
        "\n",
        "  for coluna in linha.find_all('div', class_=\"f6 color-fg-muted mt-2\"):\n",
        "    conteudos = coluna.get_text().strip().split('\\n')\n",
        "    conteudo += conteudos\n",
        "  \n",
        "  for coluna in linha.find_all('span', 'a'):\n",
        "    conteudos = coluna.get_text().strip().split('\\n')\n",
        "    conteudo += conteudos\n",
        "  \n",
        "  while conteudo:\n",
        "    \n",
        "    conteudos_extraidos = i, textos_colunas[0]+textos_colunas[2].replace(' ',''), conteudo[0], conteudo[6].strip(), conteudo[12].strip(), conteudo[-1].strip()\n",
        "    conteudo_extraido.append(conteudos_extraidos)\n",
        "\n",
        "    i+=1\n",
        "    break\n",
        "  \n",
        "print(conteudo_extraido[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5PWmHEMTRry",
        "outputId": "b39aa3e4-40ec-4047-e6dc-0d5e45aefe0d"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 'toeverything /AFFiNE', 'TypeScript', '3,792', '127', '1,156 stars today'), (2, 'utmapp /UTM', 'Swift', '14,186', '879', '295 stars today'), (3, 'NVIDIAGameWorks /kaolin-wisp', 'Python', '552', '43', '74 stars today'), (4, 'microsoft /terminal', 'C++', '84,589', '7,468', '148 stars today'), (5, 'jina-ai /discoart', 'Python', '1,963', '102', '318 stars today'), (6, 'martinshkreli /models', '297', '33', '', '71 stars today'), (7, 'facebookresearch /ParlAI', 'Python', '9,194', '1,891', '108 stars today'), (8, 'KalleHallden /exer_log', 'Dart', '113', '28', '30 stars today'), (9, 'juliocesarfort /public-pentesting-reports', 'CSS', '5,997', '1,528', '185 stars today'), (10, 'EbookFoundation /free-programming-books', '244,119', '50,166', '', '274 stars today')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lista = list()\n",
        "\n",
        "for a in range(100):\n",
        "  a\n",
        "  for i in range(10):\n",
        "    \n",
        "    lista.append(i + 1)\n",
        "    \n",
        "\n",
        "print(lista)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFy-clHyZGkw",
        "outputId": "e4511745-05c8-4a0f-80e3-a0aaf705b96b"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# d) Escrevendo o arquivo csv\n",
        "import csv\n",
        "\n",
        "with open(file='github.csv', mode='w', encoding='utf8') as arquivo:\n",
        "  csv.writer(arquivo, delimiter= ';').writerow(['Ranking', 'Project','Language', 'stars', 'Forks', 'stars_today'])\n",
        "  for i in conteudo_extraido[0:10]:\n",
        "    csv.writer(arquivo, delimiter= ';').writerow(i)"
      ],
      "metadata": {
        "id": "seGTZB964PpB"
      },
      "execution_count": 220,
      "outputs": []
    }
  ]
}